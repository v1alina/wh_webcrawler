{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065944a3-eda8-45a6-9f9c-8cba54a2a1b6",
   "metadata": {},
   "source": [
    "# White House - web crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e23c601-6a4f-4931-b08a-fa3384194ae4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from os import makedirs\n",
    "from os.path import join\n",
    "from bs4 import BeautifulSoup\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f76395-1cd4-41a8-a2be-a298f1a42070",
   "metadata": {},
   "source": [
    "---\n",
    "### Building a web crawler that downloades the headers in the Briefing Room"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c69fdc-af2d-4610-860b-5a373cc99c8a",
   "metadata": {
    "tags": []
   },
   "source": [
    "The code below, can crawl through the pages of the WH and download the html content in txt format in a folder called 'index-page'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1884969b-1fea-48b7-9c9c-fe1a98785c14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.whitehouse.gov/briefing-room/?page=0\n",
      "Saving as index-pages/0.html\n"
     ]
    }
   ],
   "source": [
    "# Setting up constant vars\n",
    "makedirs('index-pages', exist_ok=True) #creates a directory titled index pages if it does not already exist\n",
    "THE_URL = 'https://www.whitehouse.gov/briefing-room/' # our base url\n",
    "INDEX_PAGES_DIR = \"index-pages\" # the directory we set up and in which we save the sites\n",
    "\n",
    "# Page numbers to be saved:\n",
    "max_page_num = 1 #adjust this according to the max amount of pages in the Briefing Room\n",
    "\n",
    "# Loop through the urls to save them\n",
    "for page_num in range(0, max_page_num): \n",
    "    resp = requests.get(THE_URL, params={'page': page_num})\n",
    "    print(\"Downloading\", resp.url)\n",
    "    \n",
    "    fname = join(INDEX_PAGES_DIR, '{}.html'.format(page_num))\n",
    "    with open(fname, \"w\") as wf:\n",
    "        print(\"Saving as\", fname)\n",
    "        wf.write(resp.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c8de1-f632-4343-a34d-c1eb08b5b1f3",
   "metadata": {},
   "source": [
    "----\n",
    "### Parsing the HTML files, extracting URLS using Beautiful soup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d2b95f3-6db8-47ca-a3c2-0966c4f22eae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.whitehouse.gov/briefing-room/statements-releases/2023/12/17/statement-from-president-joe-biden-on-the-80th-anniversary-of-the-repeal-of-the-chinese-exclusion-act/',\n",
       " 'https://www.whitehouse.gov/briefing-room/presidential-actions/2023/12/17/president-biden-announces-presidential-delegation-to-the-state-of-kuwait-to-pay-respects-upon-the-death-of-his-highness-sheikh-nawaf-al-ahmad-al-sabah-amir-of-the-state-of-kuwait/']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for page in glob('index-pages/*.html'):\n",
    "    with open(page, 'r') as file:\n",
    "        x = file.read()\n",
    "    soup = BeautifulSoup(x, 'lxml')\n",
    "    \n",
    "    # after inspecting the HTML, I noticed all releases have the attr 'class:news-item__title', which can be used to filter only\n",
    "    # relevant links\n",
    "    releases = soup.findAll('a',attrs={'class':'news-item__title'}) \n",
    "    actual_web_links = [release['href'] for release in releases]\n",
    "\n",
    "actual_web_links[:2] # to check that we have gotten the correct links"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
